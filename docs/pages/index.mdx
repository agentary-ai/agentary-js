---
title: Agentary JS Docs
---

# Agentary JS

**A lightweight JavaScript SDK for building agentic workflows with tool calling, memory, and multi-step reasoning.**

## Features

- ðŸš€ **Flexible Inference** - Run models on-device or via cloud providers
- âš¡ **WebGPU Acceleration** - Leverage WebGPU for high-performance on-device inference (supported by [transformers.js](https://github.com/huggingface/transformers.js)) 
- â˜ï¸ **Cloud Provider Support** - Integrate with cloud LLMs via secure proxy pattern
- ðŸ¤– **Agentic Workflows** - Create and execute complex multi-step agent workflows
- ðŸ§  **Memory Management** - Smart context compression and pruning for long conversations
- ðŸ› ï¸ **Function Calling** - Built-in support for tool/function calling
- ðŸ“Š **Multi-Provider Support** - Mix device and cloud models in the same application
- ðŸ“¡ **Lifecycle Events** - Built-in event system for monitoring and debugging

## Quick Start

### Installation

For cloud-only usage:

```bash
npm install agentary-js
```

For on-device inference, install the peer dependency:

```bash
npm install agentary-js @huggingface/transformers
```

> **Note:** `@huggingface/transformers` is only required for on-device inference. Cloud-only users can skip this dependency.

### Basic Example with On-Device Inference

```javascript
import { createSession } from 'agentary-js';

const session = await createSession({
  models: [{
    runtime: 'transformers-js',
    model: 'onnx-community/Qwen3-0.6B-ONNX',
    quantization: 'q4',
    engine: 'webgpu'
  }]
});

const response = await session.createResponse('onnx-community/Qwen3-0.6B-ONNX', {
  messages: [{ role: 'user', content: 'Hello!' }]
});

if (response.type === 'streaming') {
  for await (const chunk of response.stream) {
    process.stdout.write(chunk.token);
  }
}

await session.dispose();
```

### Cloud Provider Example

```javascript
const session = await createSession({
  models: [{
    runtime: 'anthropic',
    model: 'gpt-5-nano',
    proxyUrl: 'https://your-backend.com/api/openai',
    modelProvider: 'openai'
  }]
});
```

## Why Agentary JS?

### Flexible Deployment
Choose between on-device inference (WebGPU/WASM) for privacy and zero server costs, or cloud providers for maximum performance. Mix and match based on your needs.

### Secure Cloud Integration
Cloud providers use a secure proxy pattern - your API keys stay on your backend, never exposed to the browser.

### Agentic Workflows
Build sophisticated multi-step AI agents that can think, plan, use tools, and adapt - with device or cloud models.

### Production Ready
Built with observability, error handling, memory management, and performance optimization from the ground up.

## Browser Support

- **WebGPU**: Chrome 113+, Edge 113+, Firefox with WebGPU enabled
- **WebAssembly**: All modern browsers
- **Minimum Requirements**: 4GB RAM recommended for small models

## Get Started

Ready to build? Check out the [Getting Started](/getting-started) guide.

## Community

- [GitHub Repository](https://github.com/agentary-ai/agentary-js)
- [Issue Tracker](https://github.com/agentary-ai/agentary-js/issues)
- [Discussions](https://github.com/agentary-ai/agentary-js/discussions)
# Cloud Proxy Architecture

## Overview

The CloudProvider uses a proxy pattern to keep API keys secure while enabling browser-based LLM inference.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Browser                                  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           Your Web Application                         â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚         Agentary JS SDK                          â”‚  â”‚    â”‚
â”‚  â”‚  â”‚                                                  â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”‚      CloudProvider                     â”‚    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                                        â”‚    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ SSE Streaming                       â”‚    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Retry Logic                         â”‚    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Timeout Handling                    â”‚    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â€¢ Error Management                    â”‚    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚                                                  â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â”‚ HTTPS POST                        â”‚
â”‚                              â”‚ (No API Keys!)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Your Backend Server                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Proxy Server                              â”‚    â”‚
â”‚  â”‚         (anthropic-proxy.js / openai-proxy.js)        â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  Features:                                              â”‚    â”‚
â”‚  â”‚  â€¢ API Key Management (from env vars)                  â”‚    â”‚
â”‚  â”‚  â€¢ Request Transformation                               â”‚    â”‚
â”‚  â”‚  â€¢ Response Streaming (SSE)                             â”‚    â”‚
â”‚  â”‚  â€¢ Rate Limiting                                        â”‚    â”‚
â”‚  â”‚  â€¢ Logging & Monitoring                                 â”‚    â”‚
â”‚  â”‚  â€¢ Cost Tracking                                        â”‚    â”‚
â”‚  â”‚  â€¢ Caching (optional)                                   â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â”‚ HTTPS POST                        â”‚
â”‚                              â”‚ (With API Keys)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Cloud LLM Provider                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Anthropic API   â”‚              â”‚   OpenAI API     â”‚        â”‚
â”‚  â”‚                  â”‚              â”‚                  â”‚        â”‚
â”‚  â”‚  claude-3-5-*    â”‚              â”‚   gpt-4o         â”‚        â”‚
â”‚  â”‚  claude-3-opus   â”‚              â”‚   gpt-4-turbo    â”‚        â”‚
â”‚  â”‚  claude-3-haiku  â”‚              â”‚   gpt-3.5-turbo  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Request Flow

### 1. Client Request

```typescript
// Browser: Your Application
const session = await createSession({
  models: [{
    runtime: 'anthropic',
    proxyUrl: 'https://your-backend.com/api/anthropic',
    model: 'claude-3-5-sonnet-20241022'
  }]
});

for await (const chunk of session.createResponse({
  messages: [{ role: 'user', content: 'Hello' }],
  max_tokens: 100
})) {
  console.log(chunk.token);
}
```

### 2. Request to Proxy

**CloudProvider sends:**
```http
POST https://your-backend.com/api/anthropic
Content-Type: application/json

{
  "model": "claude-3-5-sonnet-20241022",
  "messages": [
    { "role": "user", "content": "Hello" }
  ],
  "max_tokens": 100
}
```

### 3. Proxy to LLM Provider

**Proxy server forwards:**
```http
POST https://api.anthropic.com/v1/messages
x-api-key: sk-ant-xxxxx
anthropic-version: 2023-06-01
Content-Type: application/json

{
  "model": "claude-3-5-sonnet-20241022",
  "messages": [
    { "role": "user", "content": "Hello" }
  ],
  "max_tokens": 100,
  "stream": true
}
```

### 4. Streaming Response

**Proxy transforms and streams back:**
```
data: {"token":"Hello","tokenId":0,"isFirst":true,"ttfbMs":245}

data: {"token":"!","tokenId":1}

data: {"token":" How","tokenId":2}

data: {"token":" can","tokenId":3}

data: {"token":" I","tokenId":4}

data: {"token":" help","tokenId":5}

data: {"token":"?","tokenId":6,"isLast":true}

data: [DONE]
```

### 5. Client Receives Tokens

**CloudProvider yields chunks:**
```typescript
{
  token: "Hello",
  tokenId: 0,
  isFirst: true,
  ttfbMs: 245
}
{
  token: "!",
  tokenId: 1,
  isFirst: false
}
// ... more chunks
{
  token: "?",
  tokenId: 6,
  isLast: true
}
```

## Security Model

### What's Secure âœ…

1. **API Keys Never in Browser**
   - Keys stored only on backend server
   - Environment variables or secret management
   - Never exposed to client-side code

2. **HTTPS/TLS Encryption**
   - All communication encrypted
   - Protects data in transit

3. **Backend Authentication**
   - Optional: Add auth to proxy endpoints
   - JWT, OAuth, API keys for clients

4. **Rate Limiting**
   - Control usage per user/IP
   - Prevent abuse

5. **Request Validation**
   - Sanitize inputs on backend
   - Validate model names, parameters
   - Prevent prompt injection

### Best Practices ğŸ”’

```javascript
// 1. Validate requests
app.post('/api/anthropic', authenticate, async (req, res) => {
  // Check user authentication
  if (!req.user) {
    return res.status(401).json({ error: 'Unauthorized' });
  }

  // Validate model
  const allowedModels = ['claude-3-5-sonnet-20241022'];
  if (!allowedModels.includes(req.body.model)) {
    return res.status(400).json({ error: 'Invalid model' });
  }

  // Check user's rate limit
  const userLimit = await checkRateLimit(req.user.id);
  if (userLimit.exceeded) {
    return res.status(429).json({ error: 'Rate limit exceeded' });
  }

  // Forward to API...
});

// 2. Set CORS properly
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', 'https://yourdomain.com');
  // Don't use '*' in production!
  next();
});

// 3. Log all requests
app.use((req, res, next) => {
  logger.info('API Request', {
    userId: req.user?.id,
    model: req.body.model,
    timestamp: new Date().toISOString()
  });
  next();
});

// 4. Monitor costs
await db.logUsage({
  userId: req.user.id,
  model,
  tokens: tokenCount,
  cost: calculateCost(tokenCount, model),
  timestamp: Date.now()
});
```

## Error Handling Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â”‚  CloudProviderâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Proxy     â”‚
â”‚   Server     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º Network Error â”€â”€â–º ProviderNetworkError
       â”‚
       â”œâ”€â–º Timeout â”€â”€â”€â”€â”€â”€â–º ProviderTimeoutError
       â”‚
       â”œâ”€â–º 4xx Error â”€â”€â”€â”€â–º ProviderAPIError (no retry)
       â”‚
       â”œâ”€â–º 5xx Error â”€â”€â”€â”€â–º ProviderAPIError (retry with backoff)
       â”‚
       â””â”€â–º Success â”€â”€â”€â”€â”€â”€â–º Stream tokens
```

### Retry Strategy

```
Attempt 1: Immediate
          â”‚
          â”œâ”€â–º Success â”€â”€â–º Done
          â”‚
          â””â”€â–º Error
                â”‚
                â–¼
          Wait 1 second
                â”‚
Attempt 2: After 1s delay
          â”‚
          â”œâ”€â–º Success â”€â”€â–º Done
          â”‚
          â””â”€â–º Error
                â”‚
                â–¼
          Wait 2 seconds
                â”‚
Attempt 3: After 2s delay
          â”‚
          â”œâ”€â–º Success â”€â”€â–º Done
          â”‚
          â””â”€â–º Error â”€â”€â–º Throw error
```

## Scaling Considerations

### Horizontal Scaling

```
                    Load Balancer
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
    Proxy Server 1  Proxy Server 2  Proxy Server 3
         â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    LLM Provider
```

### Vertical Scaling

- Increase server CPU/RAM
- Use clustering (PM2)
- Optimize request handling

### Caching Layer

```
Browser
  â”‚
  â–¼
Proxy Server
  â”‚
  â”œâ”€â–º Redis Cache â”€â”€â–º Hit â”€â”€â–º Return cached response
  â”‚                   â”‚
  â”‚                   â””â”€â–º Miss
  â”‚                       â”‚
  â–¼                       â–¼
LLM Provider          Forward to API
  â”‚                       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         Cache result
```

### Queue System

```
High Traffic
     â”‚
     â–¼
Request Queue (Redis/RabbitMQ)
     â”‚
     â”œâ”€â–º Worker 1 â”€â”€â–º LLM Provider
     â”œâ”€â–º Worker 2 â”€â”€â–º LLM Provider
     â””â”€â–º Worker 3 â”€â”€â–º LLM Provider
```

## Monitoring & Observability

### Metrics to Track

1. **Request Metrics**
   - Requests per second
   - Success/error rates
   - Response times (p50, p95, p99)

2. **Token Metrics**
   - Tokens per request
   - Total tokens per hour/day
   - Cost per user/team

3. **Error Metrics**
   - Error rates by type
   - Retry rates
   - Timeout rates

4. **Business Metrics**
   - Active users
   - API usage trends
   - Cost per user

### Example Monitoring

```javascript
import { metrics } from './monitoring';

app.post('/api/anthropic', async (req, res) => {
  const startTime = Date.now();

  try {
    // Process request...

    metrics.increment('requests.success');
    metrics.timing('requests.duration', Date.now() - startTime);
    metrics.increment('tokens.used', tokenCount);

  } catch (error) {
    metrics.increment('requests.error');
    metrics.increment(`requests.error.${error.constructor.name}`);
  }
});
```

## Deployment Architectures

### Simple: Single Server

```
Internet â”€â”€â–º Single Node.js Server â”€â”€â–º LLM Provider
              (Express + Proxy)
```

**Pros:** Simple, cheap
**Cons:** Single point of failure

### Medium: Load Balanced

```
Internet â”€â”€â–º Load Balancer â”€â”€â”¬â”€â”€â–º Server 1 â”€â”€â”
                             â”œâ”€â”€â–º Server 2 â”€â”€â”¤â”€â”€â–º LLM Provider
                             â””â”€â”€â–º Server 3 â”€â”€â”˜
```

**Pros:** High availability, scalable
**Cons:** More complex, higher cost

### Advanced: Serverless

```
Internet â”€â”€â–º API Gateway â”€â”€â–º Lambda Functions â”€â”€â–º LLM Provider
                                  (Auto-scale)
```

**Pros:** Infinite scale, pay per request
**Cons:** Cold starts, complexity

### Enterprise: Full Stack

```
Internet
  â”‚
  â–¼
CDN (CloudFlare)
  â”‚
  â–¼
Load Balancer (AWS ALB)
  â”‚
  â”œâ”€â”€â–º API Gateway
  â”‚      â”‚
  â”‚      â”œâ”€â”€â–º Authentication Service
  â”‚      â”œâ”€â”€â–º Rate Limiter (Redis)
  â”‚      â””â”€â”€â–º Proxy Servers (ECS/K8s)
  â”‚              â”‚
  â”‚              â”œâ”€â”€â–º Cache (Redis)
  â”‚              â””â”€â”€â–º Queue (SQS)
  â”‚
  â””â”€â”€â–º Monitoring (DataDog/New Relic)
  â”‚
  â–¼
LLM Providers
```

## Next Steps

- Implement the proxy for your use case
- Add authentication and authorization
- Set up monitoring and alerting
- Deploy to production
- Scale as needed
